---
title: "An Analysis of the Next Generation of Home Video Game Consoles"
author: "10392665, 10684078, 10557474"
output: beamer_presentation

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(rtweet)
library(ggplot2)
library(dplyr)
library(ggthemes)
library(readr)
library(jsonlite)
library(tidytext)
library(wordcloud)
library(wordcloud2)
library(tidyr)
library(maps)
library(graphics)
library(lubridate)
library(ggallin)
library(patchwork)
library(knitr)



playstation_english <-  read_csv("playstation_tweets_english.csv", col_names = TRUE)
xbox_x_english <-  read_csv("xboxseriesx_tweets_english.csv", col_names = TRUE)
console_my_stop_words <- data.frame(word = c("playstation","ps5","PS5","xbox","gaming","games","game"))
```



## Xbox Series X vs Playstation 5 

<center>
![](consoles.jpg)
</center>


## Our Aims 

- Which console is going to have the more successful launch and the highest sales?
- What are the key factors that are going to influence a console purchase?
- What changes can we recommend to Sony/Microsoft to increase their respective shares of the market?

## Background

- Home console market is a $34 billion industry and is expected to grow to ~ \$52 billion by 2027.
- Microsoft and Sony have been engaged in direct competition since 2001.
- Differences between the platforms in previous generations have been large.
- Differences between the platforms in the newest generation have been minimised and services offered have been largely homogenized.


## Frequency of Tweets Containing #XboxSeriesX and #Playstation5

```{r, echo = FALSE}
tv_ps <- as.Date(as.POSIXct(playstation_english$created_at,format='%Y%M%D'))
tv_xb <- as.Date(as.POSIXct(xbox_x_english$created_at,format='%Y%M%D'))

playstation_english <- cbind(playstation_english,tv_ps)
xbox_x_english <- cbind(xbox_x_english,tv_xb)

tv_ctx <- playstation_english %>% group_by(tv_ps) %>% count()

tv_ctp <- xbox_x_english %>% group_by(tv_xb) %>% count()


ggplot() +
  geom_area(data = tv_ctp,aes(x = tv_xb, y = n, color = "#E7B800", fill = "#E7B800"),
            alpha = 0.5, position = position_dodge(0.8)) +
  geom_area(data = tv_ctx,aes(x = tv_ps, y = n,color = "#00AFBB", fill = "#00AFBB"),
            alpha = 0.5, position = position_dodge(0.8)) +
  labs(x = NULL, y = NULL,title = "Frequency of Tweets From #Xbox and #Playstation",
       subtitle = "Twitter status (tweet) counts aggregated using 1-days intervals",
       caption = "Source: Data collected from Twitter's REST API via rtweet")+
  scale_color_manual(values = c("#003087", "#0e7a0d")) +
  scale_fill_manual(values = c("#003087", "#0e7a0d"),
                    name  ="Console",
                    labels=c("Playstation", "Xbox")) +
   theme_minimal() +
  guides(color=FALSE)

```


## Tweets by Location

```{r, echo=FALSE, error = FALSE,message= FALSE, error= FALSE}

playstation_english$location[playstation_english$location==""] <- NA
#Transforms the empty values into NA's                    

re_playstation <- playstation_english %>% mutate(location_rec =
                                           recode(location, "United Kingdom" = "UK","London, England" = "UK",
                                                  "Colorado, USA" = "United States", "New Jersey USA" = "United States",
                                                  "San Francisco, CA" = "United States", "England, United Kingdom" = "UK",
                                                  "Los Angeles, CA" = "United States", "California, USA" = "United States",
                                                  "USA" = "United States", "Canada <U+0001F1E8><U+0001F1E6>" = "Canada",
                                                  "Toronto, Ontario" = "Canada", "New York, USA" = "United States",
                                                  "New York, NY" = "United States", "Bronx, NY" = "United States",
                                                  "Texas, USA" = "United States" , "Big Apple" = "United States", "Toledo/Orlando" = "United States",
                                                  "Calgary, Alberta" = "Canada", "Florida, USA" = "United States", "Ontario Canada" = "Canada",
                                                  "Melbourne, Victoria" = "Australia", "Chicago, IL" = "United States", "London" = "UK", "Lafayette, LA"
                                                  = "United States", "Sheffield, England" = "UK", "Scotland" = "UK", "North Pole, AK" = "United States",
                                                  "London" = "UK", "Chicago, IL"= "United States", "Córdoba/Spain" = "Spain",
                                                  "Florida, USA" = "United States", "London, UK" = "UK", "Sweden/Stockholm" = "Sweden",
                                                  "Caerphilly, South Wales, UK" = "UK", "Dallas, TX" = "United States", "Virginia, USA"
                                                  = "United States", "Deutschland" = "Germany", "NJ" = "UniteÃ³d States", "Seattle, WA" = 
                                                    "United States", "Bari, Puglia" = "Italy", "New York" = "United States", "Ohio, USA"=
                                                    "United States", "England" = "UK", "Atlanta, GA" = "United States", "Washington, DC"
                                                  = "United States", "New Jersey, USA" = "United States", "Manchester, England" = "UK",
                                                  "Scotland, United Kingdom" = "UK", "Nordrhein-West., DE, Iserlohn" = "Germany", "British Columbia, Canada"
                                                  = "Canada", "Brooklyn, NY" = "United States", "Nashville, TN" = "United States",
                                                  "Pennsylvania, USA" = "United States", "Perth, Western Australia" = "Australia", "Sydney, Australia" = "Australia",
                                                  "Wales, United Kingdom" = "UK", "Arizona, USA" = "United States", "East, England" = "UK"
                                                  , "San Antonio, TX" = "United States", "Toronto" = "Canada", "Glasgow, Scotland" = "UK",
                                                  "Washington D.C." = "United States", "Moscow" = "Russia", "North Carolina, USA" = "United States",
                                                  "Inglewood,Ca" = "United States", "Melbourne" = "Australia", "Melbourne, Australia" = "Australia",
                                                  "Melbourne. Australia" = "Australia", "Nova Scotia" = "Canada", "Melbourne " = "Australia", 
                                                  "Sverige" = "Sweden", "Sydney, New South Wales" = "Australia", "Garden City, KS" = "United States"))
#This renames the locations from their cities or regions and renames them to the country to get a clearer understanding of where they are all
#coming from



#proportional representation of locations by tweet 

ps_loc_graph_proportional <-  re_playstation %>%
  filter(!location_rec %in% c("Worldwide", "A PLANET N OUTER SPACE <U+0001F30D><U+0001F30D>", "Born in Night City",
                              "patreon.com/germanstrands", "Mistake Island", "Ragnarok", "Nirvana, Outer Space", "twitch.tv/xbmnetwork", "Earth", "/usr/optimus_code",
                              "Everywhere & Nowhere", "Interwebs", "XBL", "Bad Vibes Forever")) %>%
  count(location_rec, sort = TRUE) %>%  #Orders from most to least
  mutate(location_rec = reorder(location_rec,n)) %>%
  na.omit() %>%
  mutate(percentage_of_tweets = n/sum(n)) %>%
  head(10) %>% #Shows 10 results
  ggplot(aes(x = location_rec,y = percentage_of_tweets)) +
  geom_col(fill = "#003087") + 
  #mutate(location_rec = reorder(location_rec,n)) %>%
  coord_flip() +
  theme_minimal() +
  labs(x = "",
       y = "Percentage of Tweets",
       title = "PlayStation 5",caption = "Source: Data collected from Twitter's REST API via rtweet") + 
  theme(axis.text = element_text(size = 16, color = "black"), 
        axis.title = element_text(size = 16, color = "black"),
        title = element_text(size = 18)) +
  scale_y_continuous(labels = scales::percent)

#
#                          

#_____________________________________________________________________#
## XBOX SERIES X ##


xbox_x_english$location[xbox_x_english$location==""] <- NA

#Transforms the empty values into NA's    

re_xboxX <- xbox_x_english %>% mutate(location_rec =
                               recode(location, "United Kingdom" = "UK","London, England" = "UK",
                                      "Colorado, USA" = "United States", "New Jersey USA" = "United States",
                                      "San Francisco, CA" = "United States", "England, United Kingdom" = "UK",
                                      "Los Angeles, CA" = "United States", "California, USA" = "United States",
                                      "USA" = "United States", "Canada <U+0001F1E8><U+0001F1E6>" = "Canada",
                                      "Toronto, Ontario" = "Canada", "New York, USA" = "United States",
                                      "New York, NY" = "United States", "Bronx, NY" = "United States",
                                      "Texas, USA" = "United States" , "Big Apple" = "United States", "Toledo/Orlando" = "United States",
                                      "Calgary, Alberta" = "Canada", "Florida, USA" = "United States", "Ontario Canada" = "Canada",
                                      "Melbourne, Victoria" = "Australia", "Chicago, IL" = "United States", "London" = "UK", "Lafayette, LA"
                                      = "United States", "Sheffield, England" = "UK", "Scotland" = "UK", "North Pole, AK" = "United States",
                                      "London" = "UK", "Chicago, IL"= "United States", "Córdoba/Spain" = "Spain",
                                      "Florida, USA" = "United States", "London, UK" = "UK", "Sweden/Stockholm" = "Sweden",
                                      "Caerphilly, South Wales, UK" = "UK", "Dallas, TX" = "United States", "Virginia, USA"
                                      = "United States", "Deutschland" = "Germany", "NJ" = "United States", "Seattle, WA" = 
                                        "United States", "Bari, Puglia" = "Italy", "New York" = "United States", "Ohio, USA"=
                                        "United States", "England" = "UK", "Atlanta, GA" = "United States", "Washington, DC"
                                      = "United States", "New Jersey, USA" = "United States", "Manchester, England" = "UK",
                                      "Scotland, United Kingdom" = "UK", "Nordrhein-West., DE, Iserlohn" = "Germany", "British Columbia, Canada"
                                      = "Canada", "Brooklyn, NY" = "United States", "Nashville, TN" = "United States",
                                      "Pennsylvania, USA" = "United States", "Perth, Western Australia" = "Australia", "Sydney, Australia" = "Australia",
                                      "Wales, United Kingdom" = "UK", "Arizona, USA" = "United States", "East, England" = "UK"
                                      , "San Antonio, TX" = "United States", "Toronto" = "Canada", "Glasgow, Scotland" = "UK",
                                      "Washington D.C." = "United States", "Moscow" = "Russia", "North Carolina, USA" = "United States",
                                      "Inglewood,Ca" = "United States", "Melbourne" = "Australia", "Melbourne, Australia" = "Australia",
                                      "Melbourne. Australia" = "Australia", "Nova Scotia" = "Canada", "Melbourne " = "Australia", 
                                      "Sverige" = "Sweden", "Sydney, New South Wales" = "Australia", "Garden City, KS" = "United States"))



#This renames the locations from their cities or regions and renames them to the country to get a clearer understanding of where they are all
#coming from


xbox_loc_graph_proportional <- re_xboxX %>%
  filter(!location_rec %in% c("Worldwide", "A PLANET N OUTER SPACE <U+0001F30D><U+0001F30D>", "Born in Night City",
                              "patreon.com/germanstrands", "Mistake Island", "Ragnarok", "Nirvana, Outer Space", "twitch.tv/xbmnetwork", "Earth", "/usr/optimus_code",
                              "Everywhere & Nowhere", "Interwebs", "XBL", "Bad Vibes Forever")) %>%
  count(location_rec, sort = TRUE) %>%  #Orders from most to least
  mutate(location_rec = reorder(location_rec,n)) %>%
  na.omit() %>%
  mutate(percentage_of_tweets = n/sum(n)) %>%
  head(10) %>% #Shows 10 results
  ggplot(aes(x = location_rec,y = percentage_of_tweets)) +
  geom_col(fill = "#0e7a0d") + 
  #mutate(location_rec = reorder(location_rec,n)) %>%
  coord_flip() +
  theme_minimal() +
  labs(x = "Top Locations",
       y = "Percentage of Tweets",
       title = "Xbox Series X") + 
  theme(axis.text = element_text(size = 16, color = "black"), 
        axis.title = element_text(size = 16, color = "black"),
        title = element_text(size = 18)) +
  scale_y_continuous(labels = scales::percent) 



#xboxColour:#0e7a0d
#playstationColour: #003087

xbox_loc_graph_proportional + ps_loc_graph_proportional #Patchwork Lib lets you save graphs to variables and print them out right next too eachother

console_my_stop_words <- data.frame(word = c("playstation","ps5","PS5","xbox","gaming","games","game"))


#creates new data frames with the tweet number, platform, sentiment score, date of tweet
console_sentiment_analysis_prep <- function(dataframe, inputtopic){
  
  dataframe$stripped_text <- gsub("http.*","", dataframe$text)
  dataframe$stripped_text <- gsub("https.*","", dataframe$stripped_text)
  dataframe$stripped_text <- gsub("amp","", dataframe$stripped_text)
  
  intermediate1 <- dataframe %>% select(stripped_text, created_at) %>% mutate(tweet_number = row_number()) %>%
    unnest_tokens(word, stripped_text)
  
  intermediate2 <- intermediate1 %>% anti_join(stop_words) %>% anti_join(console_my_stop_words)
  
  dataframe_sentiment <- intermediate2 %>%
    inner_join(get_sentiments("bing")) %>%
    mutate(sentiment = ifelse(word == "hype", "positive", sentiment))
  
  created_list <- dataframe_sentiment %>% select(created_at, tweet_number) %>% distinct() %>% mutate(created_at = as.POSIXct(created_at))
  
  newname <- dataframe_sentiment %>% count(tweet_number, sentiment) %>%
    spread(sentiment, n, fill = 0) %>% # negative and positive sentiment in separate columns
    mutate(score = positive - negative) # score = net sentiment (positive - negative)
  
  
  
  newname <- newname %>% mutate(platform = inputtopic)
  newname <- left_join(newname, created_list, by = "tweet_number")
  
}


xbox_sentiment <- console_sentiment_analysis_prep(xbox_x_english, "Xbox_X")
playstation_sentiment <- console_sentiment_analysis_prep(playstation_english, "Playstation")

#bind dataframes, factorise platform
total_sent_cons_average <- rbind(xbox_sentiment, playstation_sentiment)
platform_sentiment <- rbind(xbox_sentiment, playstation_sentiment)
platform_f <- factor(platform_sentiment$platform)
platform_sentiment <- platform_sentiment %>% mutate(platform = platform_f, hour_of_day = hour(created_at))
total_sent_cons_average2 <- total_sent_cons_average %>% group_by(platform) %>% summarise(avg_sentiment = mean(score))
```



## Sentiment Analysis of Tweets Containing #XboxSeriesX and #Playstation5

```{r, echo=FALSE, messages = FALSE, warning = FALSE, error= FALSE}




kable(total_sent_cons_average2, 
      align = c("c", "r"), 
      col.names = c("Platform", "Average Sentiment"),
      caption = "Average Sentiments")


ttest <- t.test(score ~platform, data = platform_sentiment, var.equal = TRUE)
tpval <- ttest$p.value

```
The p.value for significant difference between Xbox and Playstation sentiment is: `r tpval`


## Sentiment Over Time


```{r, echo=FALSE, warning = FALSE, error= FALSE, message = FALSE}
console_my_stop_words <- data.frame(word = c("playstation","ps5","PS5","xbox","gaming","games","game"))


#creates new data frames with the tweet number, platform, sentiment score, date of tweet
console_sentiment_analysis_prep <- function(dataframe, inputtopic){
  
  dataframe$stripped_text <- gsub("http.*","", dataframe$text)
  dataframe$stripped_text <- gsub("https.*","", dataframe$stripped_text)
  dataframe$stripped_text <- gsub("amp","", dataframe$stripped_text)
  
  intermediate1 <- dataframe %>% select(stripped_text, created_at) %>% mutate(tweet_number = row_number()) %>%
    unnest_tokens(word, stripped_text)
  
  intermediate2 <- intermediate1 %>% anti_join(stop_words) %>% anti_join(console_my_stop_words)
  
  dataframe_sentiment <- intermediate2 %>%
    inner_join(get_sentiments("bing")) %>%
    mutate(sentiment = ifelse(word == "hype", "positive", sentiment))
  
  created_list <- dataframe_sentiment %>% select(created_at, tweet_number) %>% distinct() %>% mutate(created_at = as.POSIXct(created_at))
  
  newname <- dataframe_sentiment %>% count(tweet_number, sentiment) %>%
    spread(sentiment, n, fill = 0) %>% # negative and positive sentiment in separate columns
    mutate(score = positive - negative) # score = net sentiment (positive - negative)
  
  
  
  newname <- newname %>% mutate(platform = inputtopic)
  newname <- left_join(newname, created_list, by = "tweet_number")
  
}


xbox_sentiment <- console_sentiment_analysis_prep(xbox_x_english, "Xbox_X")
playstation_sentiment <- console_sentiment_analysis_prep(playstation_english, "Playstation")

#bind dataframes, factorise platform
total_sent_cons_average <- rbind(xbox_sentiment, playstation_sentiment)
platform_sentiment <- rbind(xbox_sentiment, playstation_sentiment)
platform_f <- factor(platform_sentiment$platform)
platform_sentiment <- platform_sentiment %>% mutate(platform = platform_f, hour_of_day = hour(created_at))


#average sentiment aggregated every 6 hours

sentiment_6_hour <- platform_sentiment %>% mutate(six_hour_intervals = cut.POSIXt(created_at, breaks = "6 hours")) %>% 
  group_by(platform, six_hour_intervals) %>% summarise(avg_sentiment = mean(score))
sentiment_6_hour <- sentiment_6_hour %>% mutate(six_hour_intervals = as.POSIXct(six_hour_intervals))

sentiment_6_hour  %>% group_by(platform) %>% ggplot(aes(x = six_hour_intervals, y = avg_sentiment, color = platform,
                                                        group = platform)) +
  geom_line(size = 1) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, size = 7, hjust = 1, vjust = 0.2)) +
  labs(x = "Time (in 6 hour intervals)", y = "Average Sentiment", color = "Platform",
       title = "Average sentiment of tweets containing #Playstation and #Xbox", caption = "Source: Data collected from Twitter's REST API via rtweet") +
       scale_color_manual(values = c("#003087", "#0e7a0d")) +
  geom_hline(yintercept=0, linetype="dashed", color = "red")

total_sent_cons_average2 <- total_sent_cons_average %>% group_by(platform) %>% summarise(avg_sentiment = mean(score))
```
 


## Emotional Sentiment 

Assigns the sentiments of each tweet to an emotion 
  
  

```{r, echo = FALSE, message = FALSE, warning= FALSE, error= FALSE, cache=TRUE}
#message= FALSE, error= FALSE, warining = FALSE
console_sentiment_analysis_prep_nrc <- function(dataframe, inputtopic){
  
  dataframe$stripped_text <- gsub("http.*","", dataframe$text)
  dataframe$stripped_text <- gsub("https.*","", dataframe$stripped_text)
  dataframe$stripped_text <- gsub("amp","", dataframe$stripped_text)
  
  intermediate1 <- dataframe %>% select(stripped_text, created_at) %>% mutate(tweet_number = row_number()) %>%
  unnest_tokens(word, stripped_text)
  intermediate2 <- intermediate1 %>% anti_join(stop_words) %>% anti_join(console_my_stop_words)

  dataframe_sentiment <- intermediate2 %>%
    inner_join(get_sentiments("nrc"))

  output <- dataframe_sentiment %>% mutate(platform = inputtopic)

  
}
#
#takes a 4k sample from each twitter data set
xbox_x_sample <- sample_n(xbox_x_english, 4000, replace = TRUE)
playstation_sample <- sample_n(playstation_english, 4000, replace = TRUE)

nrc_test_xbox <- console_sentiment_analysis_prep_nrc(xbox_x_sample, "Xbox_X")
nrc_test_playstation <- console_sentiment_analysis_prep_nrc(playstation_sample, "Playstation")
nrc_sentiment <- rbind(nrc_test_xbox, nrc_test_playstation)
platform_f <- factor(nrc_sentiment$platform)
nrc_sentiment <- nrc_sentiment %>% mutate(platform = platform_f)

#counts sentiment
nrc_sentiment_1_day <- nrc_sentiment %>%
  count(platform, sentiment)

#polar plot showing sentiment. random sample so different every time 
nrc_sentiment_1_day %>% ggplot(aes(x = sentiment, y = n, group = platform, shape = platform, color = platform)) +
  geom_point(size = 4) +
  coord_polar() +
  scale_y_log10() +
  theme_minimal() +
  geom_text(aes(label = n), size = 3, color = "black", vjust = -1) +
  labs(x = "Sentiment", y = "", color = "Platform", shape = "Platform", caption = "Source: Data collected from Twitter's REST API via rtweet")
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    plot.title = element_text(face = "bold", size = 16),
    legend.title = element_text(face = "bold", size = 14),
    axis.text.x = element_text(
      face = "bold", size = 12, color = RColorBrewer:::brewer.pal(n = 6, "YlOrBr")[2:6]
    ))

```




## Correlation Between Marketing and Sentiment

```{r, echo=FALSE, warning = FALSE, error= FALSE, message=FALSE}
platform_sentiment <- read_csv("platform_sentiment_by_tweet.csv")
import <- read_csv("playstation_xbox_official_tweets_extra.csv")


#create the appropriate 6 hour breaks 
tm <- seq(as.POSIXct("2020-10-27 05:00:00"), by = "6 hours", length.out = 38)
post_date <- import %>% select(created_at, text, screen_name)
post_date <- post_date %>% filter(created_at >= as.POSIXct('2020-10-27 05:00:00') & created_at < as.POSIXct('2020-11-05 15:31:09'))
factor_screen_name <- factor(post_date$screen_name)
post_date <- post_date %>% mutate(screen_name = factor_screen_name, six_hour_intervals = cut.POSIXt(created_at, breaks = tm))



#total the amount of posts in each interval
totals <- post_date %>% group_by(screen_name, six_hour_intervals) %>% 
  summarise(total_posts = length(six_hour_intervals)) 
totals <- na.omit(totals)
totals <- totals %>% mutate(six_hour_intervals = as.POSIXct(six_hour_intervals))            


#add back in the missing aggregations with join
test <- data.frame(screen_name = "Xbox", six_hour_intervals = tm)
test_2 <- data.frame(screen_name = "PlayStation", six_hour_intervals = tm)
test <- rbind(test, test_2)
test <- test %>% mutate(six_hour_intervals = as.POSIXct(six_hour_intervals))
totals_test <- left_join(test, totals, by = c("six_hour_intervals", "screen_name"))
totals_test$total_posts <- replace_na(totals_test$total_posts, 0)
totals_test <- totals_test %>% mutate(total_posts_previous = lag(total_posts))


#refactorise platform_sentiment
platform_sentiment <- platform_sentiment %>% 
  mutate(platform = ifelse(platform == "Xbox_X", "Xbox", "PlayStation"))
platform_f <- factor(platform_sentiment$platform)
platform_sentiment <- platform_sentiment %>%
  mutate(platform = platform_f)


#6 hour intervals sentiment
sentiment_6_hour <- platform_sentiment %>% mutate(six_hour_intervals = cut.POSIXt(created_at, breaks = "6 hours")) %>% 
  group_by(platform, six_hour_intervals) %>% summarise(avg_sentiment = mean(score))
sentiment_6_hour <- sentiment_6_hour %>% mutate(six_hour_intervals = as.POSIXct(six_hour_intervals))


#combine the dataframes 
#join by date and screenname to produce correct data frame
sentiment_marketing_combined <- left_join(sentiment_6_hour, totals_test,
                                          by = c("six_hour_intervals", "platform" = "screen_name"))




#Testing for correlation for posts on previous day

sentiment_marketing_combined %>% 
  ggplot(aes(x = total_posts_previous,
             y = avg_sentiment,
             color = platform)) +
  geom_point() +
  theme_minimal() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~platform, scales = "free") +
  labs(y = "Average Sentiment", x = "Post by Accounts on Previous Day", color = "Platform", title = "Correlation of Average Sentiment and Number of Posts by Official Marketing Accounts") +
  theme(legend.position = "none")


```

## Wordcloud: #XboxSeriesX



```{r, echo=FALSE, warning = FALSE, message=FALSE}

xbox_x_english$stripped_text <- gsub("https\\S*", "", xbox_x_english$text) 
xbox_x_english$stripped_text <-gsub("@\\S*", "", xbox_x_english$stripped_text) 
xbox_x_english$stripped_text <-gsub("amp", "", xbox_x_english$stripped_text) 


xbox_clean <- xbox_x_english %>%
  select(stripped_text) %>% 
  mutate(tweetnumber = row_number()) %>% 
  unnest_tokens(word, stripped_text)
data("stop_words")


xbox_clean_words <- xbox_clean %>%
  anti_join(stop_words)


wc_my_stop_words <- data.frame(word = c("dont", "wanna", "people", "ps5","playstation","xbox","sony","xboxseriesx",
                                     "5", "ps4", "im","xboxseriess", "xbox", "series","time","microsoft","week","playstation5","day","days"))
xbox_clean_words_2 <- xbox_clean_words %>%
  anti_join(wc_my_stop_words) 


xbox_clean_words_3 <- xbox_clean_words_2 %>%
  count(word, sort = TRUE) %>% 
  mutate(freq = n / sum(n))

with(xbox_clean_words_3, 
     wordcloud(word, freq, 
               min.freq = 1, 
               max.words = 200,
               random.order = FALSE, 
               colors = brewer.pal(8, "Dark2")))

```
  

## Wordcloud: Playstation 5

```{r, echo=FALSE,warning = FALSE, message=FALSE}
playstation_english$stripped_text <- gsub("https\\S*", "", playstation_english$text) 
playstation_english$stripped_text <-gsub("@\\S*", "", playstation_english$stripped_text) 
playstation_english$stripped_text <-gsub("amp", "", playstation_english$stripped_text) 
playstation_english$stripped_text <-gsub("[\r\n]", "", playstation_english$text)
playstation_english$stripped_text <-gsub("[[:punct:]]", "", playstation_english$text)

ps_clean <- playstation_english %>%
  select(stripped_text) %>% 
  mutate(tweetnumber = row_number()) %>% 
  unnest_tokens(word, stripped_text)

data("stop_words")

ps_clean_words <- ps_clean %>%
  anti_join(stop_words)


ps_clean_words_2 <- ps_clean_words %>%
  anti_join(wc_my_stop_words) 

ps_clean_words_3 <- ps_clean_words_2 %>%
  count(word, sort = TRUE) %>% 
  mutate(freq = n / sum(n))

with(ps_clean_words_3, 
     wordcloud(word, freq, 
               min.freq = 1, 
               max.words = 500,
               random.order = FALSE, 
               colors = brewer.pal(8, "Dark2")))


```

## Volume of Tweets Containing Topic Keywords

```{r, echo=FALSE}

topic_prep <- function(dataframe, regex, name){
  
  dataframe$stripped_text <- gsub("http.*","", dataframe$text) #strip the text of links etc etc
  dataframe$stripped_text <- gsub("https.*","", dataframe$stripped_text)
  dataframe$stripped_text <- gsub("amp","", dataframe$stripped_text)
  
  intermediate1 <- dataframe %>% select(stripped_text,created_at) %>% mutate(tweet_number = row_number()) #add tweet numbers to keep track
  
  #isolate the tweets containing the keyword from the dataframe, unnest the text into singular words and filter the stop words. 
  intermediate2 <- intermediate1 %>% filter(grepl(regex, stripped_text, ignore.case = TRUE)) %>% mutate(topic = name)
}

#search each keyword
price_ps <- topic_prep(playstation_english, "price|cost", "Price")
hardware_ps <- topic_prep(playstation_english,"hardware|ram|ssd|controller|processor|fps|rdna", "Hardware")  
design_ps <- topic_prep(playstation_english,"design|fridge", "Design (including 'fridge')")  
game_ps <- topic_prep(playstation_english,"game|games", "Games")

price_xb <- topic_prep(xbox_x_english, "price|cost", "Price")
hardware_xb <- topic_prep(xbox_x_english,"hardware|ram|ssd|controller|processor|fps|rdna", "Hardware")  
design_xb <- topic_prep(xbox_x_english,"design|fridge", "Design (including 'fridge')")  
game_xb <- topic_prep(xbox_x_english,"game|games", "Games")

#combine data frames by console
all_ps <- rbind(price_ps, hardware_ps, design_ps, game_ps)
all_xb <- rbind(price_xb, hardware_xb, design_xb, game_xb)

#count by topics
all_ps_1 <- all_ps %>% group_by(topic) %>% count()
all_xb_1 <- all_xb %>% group_by(topic) %>% count()

#make the bar into negative section 
all <- rbind(all_ps_1, within(all_xb_1, n <- -n))
all$origin <- rep(c("all_ps_1", "all_xb_1"), each = nrow(all_ps_1))


#continous scaling
ggplot(all, aes(n, topic, fill = origin)) +
  geom_col() +
  scale_x_continuous(labels = abs) +
  theme_minimal() +
  labs(x = NULL, y = NULL,
       title = "Frequency of Discussed Topics for Each Console",
       subtitle = "Tweets aggregated by keywords",
       caption = "Source: Data collected from Twitter's REST API via rtweet") +
  scale_fill_manual(name = "Console", values = c("#003087", "#0e7a0d"), 
                    labels = c("all_ps_1" = "Playstation 5", "all_xb_1" = "Xbox series X"))
```

## Most Discussed Games Within Tweet Data 

```{r,echo=FALSE}
mg_playstation_english <- playstation_english %>% select(text,created_at) %>% mutate(platform = "Playstation")
mg_xbox_x_english <- xbox_x_english %>% select(text, created_at) %>% mutate(platform = "Xbox")

mg_playstation_xbox_text <- rbind(mg_playstation_english, mg_xbox_x_english)


game_name <- c("Astro's Playroom","Demon's Souls",
               "Marvel's Spider-Man: Miles Morales","Sackboy: A Big Adventure",
               "Bugsnax","Godfall","The Pathless","Forza Horizon 4","Gears 5",
               "Gears Tactics","Grounded","Ori and the Will of the Wisps",
               "Bright Memory 1.0","Dead by Daylight","Enlisted",
               "Evergate","Manifold Garden","Tetris Effect: Connected",
               "The Touryst","The Falconeer","War Thunder",
               "Yes, Your Grace",  "Halo: Infinite", "Assassin's Creed Valhalla	",
               "Borderlands 3", "Call of Duty: Black Ops Cold War", "Cyberpunk 2077",
               "Destiny 2: Beyond Light", "Devil May Cry 5: Special Edition", "DiRT 5",
               "For Honor", "Fortnite", "Just Dance 2021", "Maneater", "Mortal Kombat 11 Ultimate",
               "NBA 2K21", "Observer: System Redux", "Planet Coaster", "Warhammer: Chaosbane - Slayer Edition",
               "Watch Dogs Legion", "Yakuza: Like a Dragon")

platform <- c("Playstation 5","Playstation 5","Playstation 5",
              "Playstation 5","Playstation 5","Playstation 5","Playstation 5",
              "Xbox Series X","Xbox Series X","Xbox Series X","Xbox Series X",
              "Xbox Series X","Xbox Series X","Xbox Series X",
              "Xbox Series X","Xbox Series X","Xbox Series X","Xbox Series X",
              "Xbox Series X","Xbox Series X","Xbox Series X","Xbox Series X",
              "Xbox Series X", "Multiplatform","Multiplatform", "Multiplatform",
              "Multiplatform", "Multiplatform", "Multiplatform", "Multiplatform",
              "Multiplatform", "Multiplatform", "Multiplatform", "Multiplatform",
              "Multiplatform", "Multiplatform", "Multiplatform", "Multiplatform",
              "Multiplatform", "Multiplatform", "Xbox Series X")

keyword <- c("astro","Souls","spiderman","sackboy","bugsnax","godfall",
             "pathless","forza","gears","tactics","grounded","wisps","bright memory",
             "daylight","enlisted","evergate","manifold","tetris",
             "touryst","falconeer","thunder","grace", "halo", "valhalla",
             "borderlands", "cod", "cyberpunk", "destiny", "devil", "dirt",
             "for honor", "fortnite", "just dance", "maneater", "mortal kombat", "nba", "observer",
             "coaster", "warhammer", "watchdogs", "yakuza")



games <- data.frame(name = game_name, keyword = keyword, platform = platform, stringsAsFactors = FALSE)


#returns the filtered tweets based on games in a dataframe
discussed_games_prep <- function(dataframe, regex, title_platform, game_name, output_frame){
  
  dataframe$stripped_text <- gsub("http.*","", dataframe$text) #strip the text of links etc etc
  dataframe$stripped_text <- gsub("https.*","", dataframe$stripped_text)
  dataframe$stripped_text <- gsub("amp","", dataframe$stripped_text)
  
  intermediate1 <- dataframe %>% select(stripped_text, created_at) %>% mutate(tweet_number = row_number()) #add tweet numbers to keep track
  
  #isolate the tweets containing the keyword from the dataframe, unnest the text into singular words and filter the stop words. 
  intermediate2 <- intermediate1 %>% filter(grepl(regex, stripped_text, ignore.case = TRUE)) %>% mutate(game = game_name, platform = title_platform)
}


#search for tweets concerning all 41 games in the dataframe and return each as a list 
games_by_volume_list <- list()
for (i in 1:length(games$name)) {
  games_by_volume_list[[i]] <- discussed_games_prep(mg_playstation_xbox_text, games$keyword[i], games$platform[i], games$name[i])
}

launch_games_tweets <- do.call(rbind, games_by_volume_list)
launch_games_tweets <- launch_games_tweets %>% group_by(game) %>%
mutate(tweet_count = n())


alt_launch_games_tweets <- do.call(rbind,games_by_volume_list)
alt_launch_games_tweets <- alt_launch_games_tweets %>% group_by(game)

alt_test <- alt_launch_games_tweets %>%
  mutate(platform = as.factor(platform))


group_game <- alt_test %>% group_by(game,platform) %>% count()
top_10 <- group_game %>% arrange(desc(n)) %>% head(10)

ggplot(top_10, aes(x = reorder(stringr::str_wrap(game,10),-n), y = n, colour = platform, fill = platform)) +
  geom_col()+
  theme_minimal() +
  theme(axis.text.x = element_text( size = 9, hjust = 0.5, vjust = 0)) +
  labs(x = "",
       y = "Number of Tweets",
       title = "Top 10 Games Mentioned in the Combined Dataset",caption = "Source: Data collected from Twitter's REST API via rtweet") + 
  theme(axis.text = element_text(size = 16, color = "black"), 
        axis.title = element_text(size = 16, color = "black"),
        title = element_text(size = 18)) +
  scale_color_manual(values = c("#FF0000", "#003087","#0e7a0d" )) +
  scale_fill_manual(values = c("#FF0000", "#003087", "#0e7a0d"))
```



## Game Sentiment by Platform


```{r, echo=FALSE, message=FALSE, warning = FALSE, error= FALSE}
#establish the top 10 discussed games by n- of tweets
top10_filter <- launch_games_tweets %>% count(game) %>% arrange(desc(n)) %>% head(10)

#filter tweet list to just have the top 10 games 
top10_tweets <- launch_games_tweets %>% filter(game %in% top10_filter$game)
console_my_stop_words <- data.frame(word = c("playstation","ps5","PS5","xbox","gaming","games","game"))

#unnest text to analyse 
top10games_unnested <- top10_tweets %>% select(stripped_text, tweet_number, created_at, platform, game) %>% unnest_tokens(word, stripped_text)

#introduce stop words 
top10games_sentiment <- top10games_unnested %>% anti_join(stop_words, by = c("word" = "word"))
#top10games_sentiment_2 <- top10games_sentiment %>%  anti_join(console_my_stop_words, by = c("word" = "word"))

#using binary sentiment library
game_sentiment <- top10games_sentiment %>%
  inner_join(get_sentiments("bing")) %>%
  mutate(sentiment = ifelse(word == "hype", "positive", sentiment))

#overall score per tweet with time included for more detailed analysis 
game_sentiment_score <- game_sentiment %>% count(tweet_number, created_at, platform, sentiment) %>%
  spread(sentiment, n, fill = 0) 
game_sentiment_score <- game_sentiment_score %>% mutate(score = positive - negative)

game_sentiment_by_platform <- game_sentiment_score %>% mutate(one_day_intervals = cut.POSIXt(created_at, breaks = "1 day")) %>% 
  group_by(platform, one_day_intervals) %>% summarise(avg_sentiment = mean(score))
game_sentiment_by_platform <- game_sentiment_by_platform %>%
  mutate(one_day_intervals = as.POSIXct(one_day_intervals))


game_sentiment_by_platform %>% ggplot(aes(x = one_day_intervals, y = avg_sentiment, color = platform,
                                                          group = platform)) +
  geom_line(size = 0.75) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, size = 7, hjust = 1, vjust = 0.2)) +
  labs(x = "Date", y = "Average Sentiment",color = "Multiplatform",
       title = "Daily Average Sentiment of Games by Platform", caption = "Source: Data collected from Twitter's REST API via rtweet")  +
  scale_color_manual(values = c("#FF0000", "#003087", "#0e7a0d")) 


```

## Games With Significant Difference in Average Sentiment 

```{r, echo=FALSE }
lm_sentiment <- lm(score ~ game, data = game_sentiment_score)

game_anova <- anova(lm_sentiment)$"Pr(>F)"[1]


#follow-up test
aov_sentiment <- aov(score ~ game, data = game_sentiment_score)

#discover how different of the sentiment of each game
follow_up <-TukeyHSD(aov_sentiment)

#discover how different of the sentiment of each game
turkey_test <- TukeyHSD(aov_sentiment)

#turn the list into dataframe
df_turkey <- do.call(rbind,lapply(turkey_test, data.frame))

#change the number of formula into decimal
options(scipen=200)

#filter the p-value which is less than 0.05
filter_tuekry <- df_turkey %>% select(p.adj) %>% filter(p.adj < 0.05)

kable(filter_tuekry, align="c")

```

## Conclusions 

- Our data suggests that Xbox is likely to have a more successful launch.
- Games will have the largest influence on the success of the console this generation over other factors that dominated discussion in previous generations.
- Sony must keep pace with Microsoft in offering enticing exclusive intellectual properties and would possibly benefit from supplying them in a similar manner to the Xbox Game Pass.
- Both companies may benefit from changing their marketing practices and improving the consistency of their social media presence.


## Limitations

- Our dataset is dedicated to English language posts on a western platform.
- Lack of Geodata in our tweets limits our ability to identify markets and develop more specific insights.
- Our marketing-sentiment correlation model could be improved and produce more informative results if we introduced more variables.
- Sentiment seems to be highly affected by intersecting topics such as game releases and delays.
- Launch success will likely be influenced by supply chain issues stemming from the global pandemic which is not accounted for in our analysis. 

## References 

- McDermott, J. (2013) ‘Xbox, Playstation gear up for bruising ad-spending battle’, Advertising Age, 84(24), p. 6
- Bulik, B. S. (2007) ‘Playstation, Xbox Regroup After Being Waxed by Wii’, Advertising Age, 78(28), pp. 3–35
- FBI102420 (2020) 'Gaming Console Market Size, Share & Industry Analysis, By Type (Home Consoles and Handheld Console (Portable and Non-Portable)), By End-use (Residential and Commercial), By Applications (Gaming and Non-Gaming), and Region Forecast, 2020-2027', Fortune Business Insights
- 'Console Wars, Video Games (24-03-2007), The Economist (London), Vol.382 (8521), p.74
- Browning, Kellen; Lohr, Steve (September 21, 2020). 'Microsoft Grabs Some of World's Biggest Games in $7.5 Billion Deal', The New York Times
- 'Playstation 5 v Xbox Series X' (07-11-2020), The Economist (London)
- Michael Andronico (21-10-2019), 'PS4 vs. Xbox One: Which Console Is Right For You?', TWICE, Vol.34 (17), p.10-11
